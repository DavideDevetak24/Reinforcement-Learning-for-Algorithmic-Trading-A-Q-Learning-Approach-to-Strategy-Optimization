---
title: "Q_Learning_Trading_Strategy"
author: "Davide"
date: "`r Sys.Date()`"
output: html_document
---


## 0. Import Libraries

```{r}
set.seed(42)
options(warn=-1)
library(tidyquant, warn.conflicts = FALSE)
library(ggplot2, warn.conflicts = FALSE)
#library(tidyverse, warn.conflicts = FALSE)
library(reshape2, warn.conflicts = FALSE)
library(TTR, warn.conflicts = FALSE)
library(tidyr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(readr)
library(tibble)
library(data.table)
library(stringr)
library(foreach)
library(doParallel)
```


## 1. Import Data

```{r}
# Import data (Source: Yahoo Finance)
raw_data <- tq_get("AAPL", from = "2014-12-31", to = "2024-12-31", get = "stock.prices")
df <- raw_data[, c("date", "close")]
head(df)
```

```{r}
# Plot the AAPL time series
ggplot(df, aes(x = date, y = close)) + 
  geom_line(color = "black") +
  labs(title = "Stock Price", y = "Price ($)", x = "") +
  theme(plot.title = element_text(hjust = 0.5))

```


## 2. Creation of Technical Indicators

### 2.1. Bollinger Bands

```{r}
# Creation of Bollinger Bands
aapl_bbands <- BBands(df$close, n = 10,sd = 2)
aapl_bbands <- aapl_bbands[,c("dn","mavg", "up")]
# Clear row names to use default indexing
rownames(aapl_bbands) <- NULL
```

### 2.2. MACD Indicator

```{r}
# Creation of MACD indicator
aapl_macd <- MACD(df$close, nFast = 12, nSlow = 24, nSig = 9, wilder=FALSE)
```

### 2.3. Plotting Bollinger Bands and MACD Indicator

```{r}
# Add the indicators to the original df
df$bb_lower <- aapl_bbands[,1]
df$bb_middle <- aapl_bbands[,2]
df$bb_upper <- aapl_bbands[,3]
df$macd <- aapl_macd[,1]
df$signal <- aapl_macd[,2]

# Drop "na" values
aapl_data <- df %>% drop_na()

head(aapl_data)
```

```{r}
# Plot Bollinger Bands
ggplot(aapl_data, aes(x = date)) +
  geom_ribbon(aes(ymin = bb_lower, ymax = bb_upper), fill = "lightgreen", alpha = 0.25) +
  geom_line(aes(y = close), color = "black", size=0.5) +
  geom_line(aes(y = bb_upper), color = "#006400", linewidth=0.1) +
  geom_line(aes(y = bb_lower), color = "#006400", linewidth=0.1) +
  geom_line(aes(y = bb_middle), color = "red", linewidth=0.2) +
  labs(title = "Bollinger Bands and Price", y = "Price ($)", x = "") + 
  theme(plot.title = element_text(hjust = 0.5))

```

```{r}
# Plot MACD and Signal line
ggplot(aapl_data, aes(x = date)) +
  geom_line(aes(y = macd), color = "blue") +
  geom_line(aes(y = signal), color = "red") +
  labs(title = "MACD and Signal Line", y = "MACD", x = "") +
  theme(plot.title = element_text(hjust = 0.5))
```

## 3. Creation of the Trading Strategy

### 3.1. Creation of the signals and position in the strategy

```{r}
# Creation of Trading Signals based on the behavior of Bollinger Bands and MACD Indicator
aapl_data$Buy_Signal <- ifelse((aapl_data$close <= aapl_data$bb_lower) &
                                 (aapl_data$macd > aapl_data$signal), 1, 0)
aapl_data$Sell_Signal <- ifelse((aapl_data$close >= aapl_data$bb_upper) &
                                  (aapl_data$macd < aapl_data$signal), 1, 0)
```

```{r}
# Trading Strategy setup
aapl_data$Position <- 0 #I set the initial position to zero (in other words "Neutral" position)
max_hold_days <- 10 #The strategy will hold the position for 10 days

current_position <- 0 #Needed to understand if the strategy is long (1), short (-1) or neutral (0)
days_in_position <- 0 #Counter for how long the strategy holds a position
```

```{r}
#Algorithm for the creation of the trading position
#The idea is to maintain the current position unless there's a different signal or threshold that indicates otherwise
for(i in 1:nrow(aapl_data)){
  #Increment days_in_position if I'm holding a long or short position
  if(current_position != 0) {
    days_in_position <- days_in_position + 1
  }
  #Based on the trading signals I have 3 options: open a new position, maintain the position, close the position
  #If the current position is zero and I have a buy or sell signal, the algorithm takes a long or a short position
  if(current_position == 0) {
    if(aapl_data$Buy_Signal[i] == 1) {
      current_position <- 1
      days_in_position <- 0 #The counter days_in_position is set to zero if a directional position is taken
    } else if(aapl_data$Sell_Signal[i] == 1) {
      current_position <- -1
      days_in_position <- 0
    }
    #If the current position is different from zero, I have two choices: maintain the position or close the position. I close the position if I have a contrary signal or I surpass max_hold_days
  } else {
    if(current_position == 1 && (aapl_data$Sell_Signal[i] == 1 || days_in_position >= max_hold_days)) {
      current_position <- 0 
      days_in_position <- 0
    }
   
    if(current_position == -1 && (aapl_data$Buy_Signal[i] == 1 || days_in_position >= max_hold_days)) {
      current_position <- 0
      days_in_position <- 0
    }
  }
  #With each iteration I am creating a vector in which I synthesize the positions in the strategy
  aapl_data$Position[i] <- current_position
}

```

### 3.2. Plot of the trading positions and Strategy return

```{r}
# Plot the trading positions
ggplot(aapl_data, aes(x = date)) +
  geom_line(aes(y = close), color = "black") +
  geom_point(data = subset(aapl_data, Position == 1), aes(y = close), color = "green", size = 2) +
  geom_point(data = subset(aapl_data, Position == -1), aes(y = close), color = "red", size = 2) +
  labs(title = "Price and Trading positions", y = "Price ($)", x = "") +
  theme(plot.title = element_text(hjust = 0.5))

```

```{r}
# Compute returns
#Added column daily_return
aapl_data <- aapl_data %>% mutate(daily_return = close / lag(close) - 1)
aapl_data <- aapl_data %>% drop_na()

#Added column strategy_return
aapl_data <- aapl_data %>% mutate(strategy_return = daily_return * lag(Position, default = 0))  

#Add cumulative_market_return and cumulative_strategy_return columns to the dataset
aapl_data <- aapl_data %>% mutate(cumulative_market_return = cumprod(1 + daily_return),
         cumulative_strategy_return = cumprod(1 + strategy_return))

```

```{r}
#Plot of the Market return and strategy return
ggplot(aapl_data, aes(x = date)) +
  geom_line(aes(y = cumulative_market_return*100, color = "Market Return"), size = 0.5) +
  geom_line(aes(y = cumulative_strategy_return*100, color = "Strategy Return"), size = 1) +
  labs(title = "Cumulative Returns: Strategy vs Market", x = "Date", y = "Cumulative Return (%)", color="Legend") +
  scale_color_manual(values = c("Market Return" = "black", "Strategy Return" = "blue")) +
  theme(plot.title = element_text(hjust = 0.5))

```


## 4. Reinforcement Learning

### 4.1. Creation of States and Actions

```{r}
#I create the State column which represents the environment of the trading strategy, then I create the possible action of the trading strategy
#State combines Bollinger Bands, MACD, trading signals and trading positions into a single categorical variable
aapl_data$State <- paste0(
  ifelse(aapl_data$close < aapl_data$bb_lower, "Below_BB", 
         ifelse(aapl_data$close > aapl_data$bb_upper, "Above_BB", "Middle_BB")),
  "_",
  ifelse(aapl_data$macd > aapl_data$signal, "MACD_Bullish", "MACD_Bearish"),
  "_",
  ifelse(aapl_data$Buy_Signal == 1, "Buy", 
         ifelse(aapl_data$Sell_Signal == 1, "Sell", "No_Signal")),
  "_",
  ifelse(aapl_data$Position == 1, "Long", 
         ifelse(aapl_data$Position == -1, "Short", "Flat"))
)

actions <- c("Long", "Short", "Flat")

#the Q-learning model will choose the best action based on the state
```

```{r}
#Dividing data in train and test respectively 80% and 20% of the total data
df_train <- aapl_data[aapl_data$date <= "2022-12-31", ]
df_test <- aapl_data[aapl_data$date > "2022-12-31", ]

#Calculating again from the new starting point cumulative_market_return and cumulative_strategy_return for fair comparison
df_test <- df_test %>% mutate(cumulative_market_return = cumprod(1 + daily_return),
         cumulative_strategy_return = cumprod(1 + strategy_return))
```

```{r}
#Creation of the Q-table where rows: states, columns: actions. Initialization with all values equal to zero
Q_table <- data.table(State = unique(df_train$State))
for (a in actions) {
  Q_table[[a]] <- 0
}

#Optimize research in the q-table by setting State as column
setkey(Q_table, State)

#Hyperparameters
alpha <- 0.1   #learning rate: how much info overrides the Q-Table
gamma <- 0.9   #discount factor: long term vs short term rewards
epsilon <- 1 #casual exploration
epsilon_decay <- 0.995 #decay of epsilon as time passes
min_epsilon <- 0.01 #minimum level of epsilon

```

```{r}
#Creation of the reward function, which is needed to update the weights of the Q-table
#I use the strategy return as a reward
reward_function <- function(row) {
  return(row$strategy_return)
}
```

```{r}
#Running the experiment multiple times to ensure reliable results
#Try parallel computing

#ideally iter should be between 30 and 100
iter <- 5 #Number of repetition of the experiment
results <- list()



###new!!!
cores=detectCores()
cl <- makeCluster(cores[1]-1)
registerDoParallel(cl)
###!!!!

#foreach
#definire prima una funzione da runnare dentro il ciclo

for (j in 1:iter) {

  for (i in 1:(nrow(df_train) - 1)) {
    #Definition of the states
    current_state <- df_train$State[i]
    next_state <- df_train$State[i + 1]
    
    #Exploration vs Exploitation: the agent explores a random action with probability epsilon, otherwise the agent selects the best action based on the current state
    #As time goes by, epsilon decays. This choice was made to make the model explore more at the beginning, while after a certain time
    if (runif(1) < epsilon) { #runif(1) creates a random number between 0 and 1
      action <- sample(actions, 1) #sample chooses a single random action
    } else {
      action <- actions[which.max(Q_table[J(current_state), ..actions])] #if runif(1)>epsilon, the agent chooses the best action
    }

    reward <- reward_function(df_train[i, ])
    
    best_future_q <- max(Q_table[J(next_state), ..actions], na.rm = TRUE)
    Q_table[J(current_state), (action) := (1 - alpha) * get(action) + alpha * (reward + gamma * best_future_q)]

    epsilon <- max(min_epsilon, epsilon * epsilon_decay)
  }

  df_train$RL_Position <- 0  
  for (i in 1:(nrow(df_train) - 1)) {
    state <- df_train$State[i]
    action <- actions[which.max(Q_table[J(state), ..actions])]
    if (action == "Long") {
      df_train$RL_Position[i] <- 1
    } else if (action == "Short") {
      df_train$RL_Position[i] <- -1
    } else {
      df_train$RL_Position[i] <- 0
    }
  }

  df_train$RL_strategy_return <- df_train$daily_return * df_train$RL_Position
  df_train$cumulative_RL_return <- cumsum(df_train$RL_strategy_return)
  df_train$cumulative_RL_return <- 1 + (df_train$cumulative_RL_return - df_train$cumulative_RL_return[1])

  results[[j]] <- data.frame(date = df_train$date, cumulative_RL_return = df_train$cumulative_RL_return)
}


###New part!!!
stopCluster(cl)

#try to add time and compare time of chunk execution
```

```{r}
Q_table
```

```{r}
avg_cumulative_RL_return <- Reduce("+", lapply(results, function(x) x$cumulative_RL_return)) / iter

df_train$avg_cumulative_RL_return <- avg_cumulative_RL_return

ggplot(df_train, aes(x = date)) +
  geom_line(aes(y = cumulative_market_return*100, color = "Market")) +
  geom_line(aes(y = cumulative_strategy_return*100, color = "Bollinger & MACD")) +
  geom_line(aes(y = avg_cumulative_RL_return*100, color = "Q-Learning RL (Avg)")) +
  labs(title = "Comparison Strategy RL vs Bollinger & MACD", y = "Return (%)", x = "", color="Legend") +
  scale_color_manual(values = c("Market" = "blue", "Bollinger & MACD" = "green", "Q-Learning RL (Avg)" = "red")) +
  theme(plot.title = element_text(hjust = 0.5))

```

# Using Test Data

```{r}
df_test$RL_Position <- 0  
  for (i in 1:(nrow(df_test) - 1)) {
    state <- df_test$State[i]
    action <- actions[which.max(Q_table[J(state), ..actions])]
    
    if (action == "Long") {
      df_test$RL_Position[i] <- 1
    } else if (action == "Short") {
      df_test$RL_Position[i] <- -1
    } else {
      df_test$RL_Position[i] <- 0
    }
  }
```

```{r}
#I calculate returns
df_test$RL_strategy_return <- df_test$daily_return * df_test$RL_Position
  df_test$cumulative_RL_return <- cumsum(df_test$RL_strategy_return)
  df_test$cumulative_RL_return <- 1 + (df_test$cumulative_RL_return - df_test$cumulative_RL_return[1])

```

```{r}
#Plotting test results
ggplot(df_test, aes(x = date)) +
  geom_line(aes(y = cumulative_market_return*100, color = "Market")) +
  geom_line(aes(y = cumulative_strategy_return*100, color = "Bollinger & MACD")) +
  geom_line(aes(y = cumulative_RL_return*100, color = "Q-Learning RL (Avg)")) +
  labs(title = "Comparison Strategy RL vs Bollinger & MACD", y = "Return (%)", x = "", color="Legend") +
  scale_color_manual(values = c("Market" = "blue", "Bollinger & MACD" = "green", "Q-Learning RL (Avg)" = "red")) +
  theme(plot.title = element_text(hjust = 0.5))

```




